{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "    <a href=\"https://github.com/isa-ipa\">\n",
    "        <img src=\"\" width=\"60\" align=\"right\">\n",
    "     </a>\n",
    "     <h1>\n",
    "         Intelligent Agent Workshop: Virtual Assistant: Job & Cover Letter\n",
    "     </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda:\n",
    "\n",
    "\n",
    "In this workshop, we are to build a JobApplicationAssistant which will monitor \"Job Opportunities\" email from the provided email. Based on the user's \"Resume/CV\" and job desciption, the agent can generate tailored cover letters for job appication.\n",
    "    \n",
    "- Prepare Environment\n",
    "\n",
    "- Recap of web based image search\n",
    "\n",
    "- Virtual Assistant for Job Applicatio & Cover Letter\n",
    "\n",
    "    - Exercise 1: Get all the \"job opportunites\" related link from the email\n",
    "    - Using Local AI Components (NLP) to generate the coverletter\n",
    "    - Exercise 2: using python script sendback the application emails\n",
    "    - Exercise 3: Using TagUI-Python sendback the application emails\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info alertdanger\" style=\"margin-top: 20px\">\n",
    "    <h1>\n",
    "         Prepare Environment\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Prepare system level environment\n",
    "\n",
    "1. If you are using the ISS-VM and you also open this notebook with iss-env-py3\n",
    "    The environment is already prepared. Please go through the notebook to learn how to use tagui and do some demo application.\n",
    "2. To download ISS-VM from: https://github.com/telescopeuser/iss-vm\n",
    "3. Install the Chrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please uncomment and copy the below line into the Terminal to install the requirements\n",
    "# Don't forget to change the conda environment where you use to open this notebook\n",
    "\n",
    "# For ISS-VM user, open terminal, key in: \n",
    "# source activate iss-env-py3\n",
    "# sudo bash ./prepare.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare notebook environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this workshop, we will introduce the TagUI(https://github.com/kelaberetiv/TagUI) as the RPA tools(robotic process automation) and use TagUI-Python(https://github.com/tebelorg/RPA-Python) to do some application to help you understand the how the RPA work and how to use it in the real world task\n",
    "\n",
    "*tip: the TagUI-Python now also is called RPA-python the Rename Detail is here https://github.com/tebelorg/RPA-Python/issues/100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TagUI:\n",
    "    - TagUI is a command-line tool for digital process automation (RPA)\n",
    "    - automate Chrome in visible / invisible mode\n",
    "    - visual automation of websites and desktop\n",
    "    - write in 20+ human languages & JavaScript\n",
    "    - Chrome extension for recording web actions\n",
    "    - Python & R integrations for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please uncomment and press shift+enter to install some requirements\n",
    "# !pip install rpa sklearn nltk lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, Latex\n",
    "import codehelper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optionally, change the sourcecode of tagui command-line to launch the chrome in the incognito model to prevent some login issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set \"incognito mode\"\n",
    "!sed -i 's/chrome_started=\"$(uname -s)\"; chrome_switches=\"--user-data-dir=chrome\\/tagui_user_profile --remote-debugging-port=9222 about:blank\"/chrome_started=\"$(uname -s)\"; chrome_switches=\"--user-data-dir=chrome\\/tagui_user_profile --remote-debugging-port=9222 -incognito about:blank\"/g' ~/.tagui/src/tagui\n",
    "\n",
    "# set \"normal mode\"\n",
    "# !sed -i 's/chrome_started=\"$(uname -s)\"; chrome_switches=\"--user-data-dir=chrome\\/tagui_user_profile --remote-debugging-port=9222 -incognito about:blank\"/chrome_started=\"$(uname -s)\"; chrome_switches=\"--user-data-dir=chrome\\/tagui_user_profile --remote-debugging-port=9222 about:blank\"/g' ~/.tagui/src/tagui\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info alertdanger\" style=\"margin-top: 20px\">\n",
    "    <h1>\n",
    "         Recap of web based image search\n",
    "    </h1>\n",
    "    <p>\n",
    "        Recall the \"use the Bing Image Search to search the related image\" task in previous workshop\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import rpa as t for the new vision of TagUI same function just different name\n",
    "import tagui as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RPA][ERROR] - use init() before using close()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_image = 'exercise_3/sample.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.init()\n",
    "t.url('https://www.bing.com/?scope=images&nr=1&FORM=NOFORM')\n",
    "t.click('//div[@id=\"sb_sbi\"]')\n",
    "t.upload(\"input.fileinput\",target_image)\n",
    "t.wait(3)\n",
    "t.click('//li[contains(string(),\"Similar\")]')\n",
    "image_nums = t.count('//a[@class=\"richImgLnk\"]')\n",
    "limitation = 3\n",
    "for i in range(1,image_nums):\n",
    "    if i <= 3:\n",
    "        url = 'https://www.bing.com'+ t.read(f'(//a[@class=\"richImgLnk\"])[{i}]/img/@src')\n",
    "        t.download(url,'exercise_3/' + 'similar_'+str(i)+'.png')\n",
    "t.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "![Similar](exercise_3/similar_1.png)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown('![Similar](exercise_3/similar_1.png)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncommnet below, then press Shift+Enter for solution\n",
    "# codehelper.hint_for_ipa_recap_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Great recap! Let's now deep drive in the this process\n",
    "- 1. we upload a image\n",
    "- 2. Bing get the image file and do some magic process, then back the result\n",
    "- 3. we download top threes similar images\n",
    "\n",
    "Intelligent process automation process\n",
    "- We use tagui-bot to upload and download the image;\n",
    "- We use tagui-bot to retrieve similar image from Bing Image Search;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info alertdanger\" style=\"margin-top: 20px\">\n",
    "    <h1>\n",
    "       Virtual Assistant\n",
    "    </h1>\n",
    "    <p>\n",
    "       for Job Applicatio & Cover Letter\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IPA Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are to build a JobApplicationAssistant which will monitor \"Job Opportunities\" email from the provided email. Based on the user's \"Resume/CV\" and job desciption, the agent can generate tailored cover letters for job appication via eamil."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IPA Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. First: Monitor and retieve job opportunities \n",
    "\n",
    "    Get the job description from the target email account\n",
    "        - Login the mail\n",
    "        - Search the job description emails\n",
    "        - Download the job description files\n",
    "        \n",
    "### 2. Second: Write cover letter \n",
    "\n",
    "    Use local AI module to conduct text/language processing and generate the coverletters based on the Job Description and the Resume\n",
    "\n",
    "### 3. Third: Send job application via email \n",
    "\n",
    "    In this part, we use both pure python method and tagui to send the email to the hiring company\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success alertdanger\" style=\"margin-top: 20px\">\n",
    "    <h1>\n",
    "        First: Monitor and retieve job opportunities\n",
    "    </h1>\n",
    "    <p>\n",
    "        Get the job description from the target email account\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n",
    "    <h1>\n",
    "         Workshop Quiz:\n",
    "    </h1>\n",
    "    <p>\n",
    "         Login the target Email Account\n",
    "    </p>\n",
    "    <p>\n",
    "         <b>(Recap earlier IPA workshop Tutorial)</b>\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or use below 'filling the blank' coding template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/sf_vm_shared_folder/S-IPA-WS-UAT/part2/JobApplicationAssistant\n"
     ]
    }
   ],
   "source": [
    "import tagui as t\n",
    "import os\n",
    "\n",
    "CURRENT_PATH = os.getcwd()\n",
    "\n",
    "print(CURRENT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hover_and_read(selector):\n",
    "    t.hover(selector)\n",
    "    str = t.read(selector)\n",
    "    return str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RPA][ERROR] - use init() before using close()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'email': 'ipa_bot@hotmail.com', 'password': 'IPAagent123;'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "email_info = None\n",
    "with open(\"./email_info.json\",'r') as load_f:\n",
    "    email_info = json.load(load_f)\n",
    "    \n",
    "email_info = email_info['1']\n",
    "email_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = \"XU JIACHEN\"\n",
    "# phone = \"+65 93752168\"\n",
    "name = \"Virtual Assistant on behalf of Mr. ISS NUS\"\n",
    "phone = \"+65 6601 3161\"\n",
    "\n",
    "# Please uncomment next line please change to your own email address\n",
    "#company_emails = ['liyingxujiachen@gmail.com']\n",
    "company_emails = ['bwbw75@gmail.com']\n",
    "resume_file_path = os.path.join(CURRENT_PATH,\"resume/resume.pdf\")\n",
    "# maybe you chang to your own resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code below\n",
    "def loginEmail_outlook(email_account,email_pwd):\n",
    "    try:\n",
    "        t.init(visual_automation = True)\n",
    "        t.url('https://login.live.com/login.srf?wa=wsignin1.0&rpsnv=13&ct=1580788659&rver=7.0.6737.0&wp=MBI_SSL&wreply=https%3a%2f%2foutlook.live.com%2fowa%2f%3fnlp%3d1%26RpsCsrfState%3dd234420e-f55a-d62c-a8e6-c1c9a31e4e54&id=292841&aadredir=1&CBCXT=out&lw=1&fl=dob%2cflname%2cwld&cobrandid=90015')\n",
    "        t.type('//input[@name=\"loginfmt\"]', email_account + '[enter]')\n",
    "        t.wait(0.5)\n",
    "        t.type('//input[@name=\"passwd\"]', email_pwd + '[enter]')\n",
    "        t.wait(1)\n",
    "    except:\n",
    "        t.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    loginEmail_outlook(email_info['email'],email_info['password'])\n",
    "finally:\n",
    "    t.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncommnet below, then press Shift+Enter for solution\n",
    "# codehelper.hint_for_ipa_recap_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n",
    "    <h1>\n",
    "         Workshop Quiz:\n",
    "    </h1>\n",
    "    <p>\n",
    "         Download the Job Description files from email being monitored\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or use below 'filling the blank' coding template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getJobDescription():\n",
    "    try:\n",
    "        t.click('//input[@placeholder=\"Search\"]')\n",
    "        t.click('//button[@id=\"filtersButtonId\"]')\n",
    "        t.click('//span[contains(@class,\"ms-Dropdown-caretDownWrapper\")]')\n",
    "        t.click('//button[@title=\"Inbox\"]')\n",
    "        t.type('(//input[@id=\"From-PICKER-ID\"])','liyingxujiachen' + '[enter]')\n",
    "        # t.type('(//input[@id=\"From-PICKER-ID\"])','nustalentconnect@csm.symplicity.com' + '[enter]')\n",
    "        t.wait(1)\n",
    "        t.type('//input[@id=\"Keywords-ID\"]','job opportunity')\n",
    "        t.wait(1)\n",
    "        t.click('//button[@aria-label=\"Search\"]')\n",
    "        t.wait(3)\n",
    "        num_email=t.count('//div[@class=\"_1hHMVrN7VV4d6Ylz-FsMuP _18LAllQi61d4a4XNAr9prg\"]')\n",
    "        print('The number of job opportunity emails is: ',num_email)\n",
    "        jd_files=[]\n",
    "        for n in range(1,num_email+1):\n",
    "            t.click(f'(//div[@class=\"_1hHMVrN7VV4d6Ylz-FsMuP _18LAllQi61d4a4XNAr9prg\"])[{n}]')\n",
    "            jd_files.append(os.path.join(CURRENT_PATH,hover_and_read('//a[@target=\"_blank\"]/@href').split(\"location=./\")[-1]))\n",
    "            print(\"Thoes job opportunities files \",jd_files)\n",
    "        return jd_files\n",
    "    finally:\n",
    "        t.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of job opportunity emails is:  2\n",
      "Thoes job opportunities files  ['/media/sf_vm_shared_folder/S-IPA-WS-UAT/part2/JobApplicationAssistant/jd/1.pdf']\n",
      "Thoes job opportunities files  ['/media/sf_vm_shared_folder/S-IPA-WS-UAT/part2/JobApplicationAssistant/jd/1.pdf', '/media/sf_vm_shared_folder/S-IPA-WS-UAT/part2/JobApplicationAssistant/jd/0.pdf']\n",
      "[RPA][ERROR] - use init() before using close()\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    loginEmail_outlook(email_info['email'],email_info['password'])\n",
    "    t.wait(10)\n",
    "    jd_files = getJobDescription()\n",
    "finally:\n",
    "    t.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/media/sf_vm_shared_folder/S-IPA-WS-UAT/part2/JobApplicationAssistant/jd/5.pdf', '/media/sf_vm_shared_folder/S-IPA-WS-UAT/part2/JobApplicationAssistant/jd/4.pdf', '/media/sf_vm_shared_folder/S-IPA-WS-UAT/part2/JobApplicationAssistant/jd/3.pdf', '/media/sf_vm_shared_folder/S-IPA-WS-UAT/part2/JobApplicationAssistant/jd/2.pdf', '/media/sf_vm_shared_folder/S-IPA-WS-UAT/part2/JobApplicationAssistant/jd/1.pdf', '/media/sf_vm_shared_folder/S-IPA-WS-UAT/part2/JobApplicationAssistant/jd/0.pdf']\n"
     ]
    }
   ],
   "source": [
    "print(jd_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jd_files2 = ['/media/sf_vm_shared_folder/S-IPA-WS-UAT/part2/JobApplicationAssistant/jd/5.pdf',\n",
    "#              '/media/sf_vm_shared_folder/S-IPA-WS-UAT/part2/JobApplicationAssistant/jd/4.pdf',\n",
    "#              '/media/sf_vm_shared_folder/S-IPA-WS-UAT/part2/JobApplicationAssistant/jd/3.pdf',\n",
    "#              '/media/sf_vm_shared_folder/S-IPA-WS-UAT/part2/JobApplicationAssistant/jd/2.pdf',\n",
    "#              '/media/sf_vm_shared_folder/S-IPA-WS-UAT/part2/JobApplicationAssistant/jd/1.pdf', \n",
    "#              '/media/sf_vm_shared_folder/S-IPA-WS-UAT/part2/JobApplicationAssistant/jd/0.pdf']\n",
    "\n",
    "# jd_files = jd_files2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncommnet below, then press Shift+Enter for solution\n",
    "# codehelper.hint_for_ipa_exercise_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RPA][ERROR] - use init() before using close()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success alertdanger\" style=\"margin-top: 20px\">\n",
    "    <h1>\n",
    "        Second: Write cover letter\n",
    "    </h1>\n",
    "    <p>\n",
    "        Use local AI module to conduct text/language processing and generate the coverletters based on the Job Description and the Resume\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/sf_vm_shared_folder/S-IPA-WS-UAT/part2/JobApplicationAssistant/resume/resume.pdf'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/sf_vm_shared_folder/S-IPA-WS-UAT/part2/JobApplicationAssistant/jd/5.pdf',\n",
       " '/media/sf_vm_shared_folder/S-IPA-WS-UAT/part2/JobApplicationAssistant/jd/4.pdf',\n",
       " '/media/sf_vm_shared_folder/S-IPA-WS-UAT/part2/JobApplicationAssistant/jd/3.pdf',\n",
       " '/media/sf_vm_shared_folder/S-IPA-WS-UAT/part2/JobApplicationAssistant/jd/2.pdf',\n",
       " '/media/sf_vm_shared_folder/S-IPA-WS-UAT/part2/JobApplicationAssistant/jd/1.pdf',\n",
       " '/media/sf_vm_shared_folder/S-IPA-WS-UAT/part2/JobApplicationAssistant/jd/0.pdf']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jd_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the resume\n",
      "Converting pdf to html and txt file ...\n",
      "Extracting project information...\n",
      "Processing the resume done\n",
      "Processing the jds\n",
      "5.pdf\n",
      "Converting job pdf to html and txt...\n",
      "Extracting job information...\n",
      "4.pdf\n",
      "Converting job pdf to html and txt...\n",
      "Extracting job information...\n",
      "3.pdf\n",
      "Converting job pdf to html and txt...\n",
      "Extracting job information...\n",
      "2.pdf\n",
      "Converting job pdf to html and txt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iss-user/anaconda3/envs/iss-env-py3/lib/python3.6/site-packages/numpy/lib/function_base.py:390: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/iss-user/anaconda3/envs/iss-env-py3/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting job information...\n",
      "1.pdf\n",
      "Converting job pdf to html and txt...\n",
      "Extracting job information...\n",
      "0.pdf\n",
      "Converting job pdf to html and txt...\n",
      "Extracting job information...\n",
      "Processing the jds,done\n",
      "Generating CoverLetter\n",
      "Extracting email...\n",
      "Extracting phone...\n",
      "Extracting json from project and education experience...\n",
      "[{'date': '[]-[]', 'school': 'Koc University '}, {'date': '[]-[]', 'school': '.Zirve University '}]\n",
      "setting derived fields...\n",
      "Extracting job information...\n",
      "{'DELIVERY CONSULTANT â\\x80\\x93 Primary focus â\\x80\\x93 Data Analytics\\n\\nJOB DESCRIPTION-->1': ['Department:                     LEAP Delivery Team'], '                                Senior Specialist â\\x80\\x93 Professional Services & Onboarding\\n\\nJob Title:-->3': ['                                (Delivery Consultant â\\x80\\x93 Data Analytics)'], 'The Ideal Candidate-->4': ['You are a highly motivated, dynamic and adaptable team contributor who thrives in an innovative,', 'performance-oriented environment. Continual learning is everything and you want to be a key', 'contributor in a team full of diverse, experienced technology and business professionals. Deep down', 'you have a passion for life, embrace change and thrive in a creative environment. You understand', 'what motivates customers and team members alike and you find solutions to their problems that are', 'economic, strategic and elegant.', 'You enjoy and have experience in both â\\x80\\x9chands-on technicalâ\\x80\\x9d and â\\x80\\x9cbusiness/data analysisâ\\x80\\x9d roles.', 'You are excited by working with data analytics with a focus on efficiency, simplicity and building high', 'impact customer features.', 'You may have been called a Power User, Solution Specialist, or Architect. You have also been a software', 'developer and have experience managing and serving customers. You understand that the work you do', 'will change how organizations and the industry can access, explore, and execute data. Towards this', 'end you will be responsible for engaging with our customers to â\\x80\\x9cimplement Datameer solutionsâ\\x80\\x9d', 'among other analytics solutions and help users from various business roles leverage it effectively to', 'solve their technical and strategic needs. For e.g.,', '     â\\x96ª Help Data Engineers get ahead of all their data demands, quickly transforming raw data into', '         analytics-ready datasets', '     â\\x96ª Understand needs of Business Analysts to access more data and get answers to their questions', '         in hours, not weeks. Empower and help them shape data with point-and-click tools and start', '         discovering business-changing insights.', '     â\\x96ª Work with Data Scientists to help them explore all the data for agile and more accurate ML and', '         AI projects, performing point-and-click algorithmic and statistical analysis for faster, easier', '         feature engineering.', 'You understand what motivates customers and team members alike and you find solutions to their', 'problems that are economic, strategic and elegant.', 'Joining the LEAP team gives you the opportunity to: work on disruptive products and technologies still', 'in its very early stages, solving challenging problems that will revolutionize enterprise computing in', 'the cloud.', 'As a key technologist and practitioner, in the Data Analytics space you will be sought after for your', 'knowledge by your colleagues, peers and by our customers for your expertise and insights.'], 'Your Purpose:-->5': ['In this role, you will be a key member of LEAPâ\\x80\\x99s Professional Services Organization, and the point', 'person for Data Analytics.', '\\x0cAs the Senior Data Analytics Specialist, you will own and manage the implementation of analytics', 'solutions for our customers. Leveraging your experience and insights into how organizations access,', 'explore, and execute data you will engage with our customers to â\\x80\\x9cimplement Datameer solutionsâ\\x80\\x9d', 'among other analytics solutions and help users from various business roles leverage it effectively to', 'solve their technical and strategic needs. For example,', '    â\\x96ª Help Data Engineers get ahead of all their data demands, quickly transforming raw data into', '         analytics-ready datasets', '    â\\x96ª Understand needs of Business Analysts to access more data and get answers to their questions', '         in hours, not weeks. Empower and help them shape data with point-and-click tools and start', '         discovering business-changing insights.', '    â\\x96ª Work with Data Scientists to help them explore all the data for agile and more accurate ML and', '         AI projects, performing point-and-click algorithmic and statistical analysis for faster, easier', '         feature engineering.', 'The Delivery Consultant (Analytics) will drive implementation, adoption, retention of Datameer and', 'associate solutions, in a customer centric manner to ensure overall success and satisfaction of your', 'customers.'], 'Consulting-->7': ['   â\\x96ª Lead customer teams and projects for our customers; be the face of Datameer to the project', '        team during your scoped project.', '   â\\x96ª Interface with customers to gather requirements and articulate technical design of a solution', '        to customer.', '   â\\x96ª Conceptualization, Design (both High Level & Low Level) of comprehensive Data Analytics â\\x80\\x93', '        Big Data Solutions.', '   â\\x96ª Implementation of solutions and products of different types (with a focus on Datameer', '        Solutions) during all stages of the project lifecycle including Technical Design specification,', '        Integration of the solution, Operationalization (Training & process change), Customer', '        Adoption and Business Value Realisation', '   â\\x96ª Create strong relationships, train others and evangelize your findings and implications.', '   â\\x96ª Scope project work, maintain project status, communicate status, issues, risks, and escalate as', '        appropriate within Datameer and with Customer teams.', '   â\\x96ª Interface and collaborate with customer and Datameer team members both in project and', '        outside, including other consultants and program management.', '   â\\x96ª Provide hands on implementation, troubleshooting, and instruction in a customer facing role.', '   â\\x96ª Estimate efforts required to deliver a fully tested solution to customers, this may include', '        integrations leveraging SDK, REST APIâ\\x80\\x99s, or other programmatic approaches.'], 'Technical-->8\\n   â\\x96ª â\\x80\\x9cFull Datameer lifecycle ownershipâ\\x80\\x9d including installation through to analytical business\\n       outcomes; this requires a broad range of skills in the areas of analytics, data management,\\n       programming, and infrastructure architecture.\\n   â\\x96ª Integrate Datameer with tools and cloud-based platforms within the big data ecosystem (e.g.\\n       Hadoop, Spark, Tez, Azure HDI, Amazon EMR, RedShift, Google DataProc etcâ\\x80¦).\\n   â\\x96ª Design and develop plugins and extension services to aid customer users in data discovery,\\n       data preparation and analytics use cases.\\n   â\\x96ª Interface with Datameer engineering groups to initiate product changes; be the customer\\n       advocate and represent the business to technology and technology to business.\\n\\x0c    â\\x96ª   Design, build and maintain distributed data processing components driving the core of the\\n        Datameer application stack.\\n   â\\x96ª Influence product strategy and help drive product roadmap while developing cloud native\\n        analytics features against multiple public cloud platforms.\\n   â\\x96ª Provide architectural guidance for both on-premise and cloud rollouts.\\n   â\\x96ª Assist with application migrations of Datameer and guide strategy for data migrations.\\n\\nAnalytics-->9': ['   â\\x96ª Lead business and data analytics teams to identify and define valuable outcomes.', '   â\\x96ª Design, build, and mentor customer use cases and analytics.', '   â\\x96ª Provide best practices and tools to assist with data preparation and ETL/ELT project work.', '   â\\x96ª Hands on experience of conducting due diligence, data analysis and dependency assessment', '        required for successfully delivering the project.', '   â\\x96ª Participate in contract negotiation, proof of value execution and other late-stage presales', '        activities', '   â\\x96ª Should work in agile manner using backlogs, sprints and Kanban', '   â\\x96ª Able to assist in proposal writing, including proactive input for proposals and RFI/RFP', '        responses', '   â\\x96ª Accountable for implementation and customer success'], 'Preferred Experiences-->11': ['        â\\x96ª   5-6 years of relevant experience in consulting, technical support, professional services, or', '            systems engineering in a customer facing role.', '        â\\x96ª   At least 3-5 years software programming experience. Preferably with Java and related JVM', '            technologies.', '        â\\x96ª   Knowledge of professional software engineering best practices for the full software', '            development life cycle.', '        â\\x96ª   Applied experience with analytical programming such as Python or R to create data', '            pipelines, machine learning models, or business intelligence discoveries. (Good to Have)', '        â\\x96ª   Experience with cloud data technologies like EC2, EMR, RedShift, Azure HDI, Azure Data', '            Lake.', '        â\\x96ª   Proficiency in Linux operating systems including shell script authoring; experience with', '            distributed systems like Hadoop a big plus', '        â\\x96ª   Experience with Big Data related tools and technologies: MapReduce/Tez, HDFS,', '            HBase, Hive, Hadoop, Spark and Cloud Infrastructure providers: AWS, Azure, Google Cloud', '            will be considered an asset.', '        â\\x96ª   Experience with distributed data processing, in memory technologies, data flow', '            optimization, distributed search, cluster resource management, etc.', '        â\\x96ª   Familiarity with SQL and NoSQL databases (i.e. MySQL, Spark, etc.), data streaming and', '            integrating unstructured data will be plus.', '        â\\x96ª   Analytical experience, understanding the value that data can offer to a business unit is', '            preferred.', '        â\\x96ª   Ability to work and thrive in a fast-paced environment, learn rapidly and master diverse', '            technologies and techniques. Willingness to roll up the sleeves in a fast-paced, highly', '            varied environment', '        â\\x96ª   Demonstrated excellence in the following three categories:', '             o Consulting: discovery, analysis, listening, communication, and project leadership', '             o Analytics: given a dataset, you can extract insights and craft a compelling', '                 presentation', '             o Technical: proven comfort getting your hands dirty with SQL, relational databases,', '                 APIs', '        â\\x96ª   Strong interpersonal and collaboration skills; proven ability to build relationships', '\\x0c       â\\x96ª   Strong executive presentation and persuasion skills; excellent deliverable creation', '           and editing skills. Be prepared to show samples or present', '       â\\x96ª   Experience with Agile development teams and excellent interpersonal skills.', '       â\\x96ª   Demonstrated experience with agile project management and comfort with project', '           management concepts.', '       â\\x96ª   Organized thinker, high level of communication to people of various technical skill set and', '           acumen.', '       â\\x96ª   Availability to travel to customer sites; up to 50%+ travel.', '       â\\x96ª   Strong Communication Skills in English; addnl. ASEAN languages a plus'], 'Must Have Requirements-->15': ['       1. Conceptualization, Design (both High Level & Low Level) of comprehensive Data Analytics', '          â\\x80\\x93 Big Data Solutions.', '       2. Lead business and data analytics teams to identify and define valuable outcomes.', '       3. Design, build, and mentor customer use cases and analytics.', '       4. Tool & Solution Implementation and Use.', '       5. Provide best practices and tools to assist with data preparation and ETL/ELT project', '          work.', '       6. Hands on experience of conducting due diligence, data analysis and dependency', '          assessment required for successfully delivering the project.', '       7. Professional certification & knowledge in at Hadoop / RedShift/ Azure HDI/ Azure Data', '          Lake or any ELT / ETL Tool'], 'Good to Have Requirements-->17': ['       1. Applied experience with analytical programming such as Python or R to create data', '          pipelines, machine learning models, or business intelligence discoveries.', '       2. Experience with cloud data technologies like EC2, EMR, RedShift, Azure HDI, Azure Data', '          Lake.', '       3. Experience with Big Data related tools and technologies: MapReduce/Tez, HDFS,', '          HBase, Hive, Hadoop, Spark and Cloud Infrastructure providers: AWS, Azure, Google Cloud', '          will be considered an asset.', '       4. Proficiency in Linux operating systems including shell script authoring; experience with', '          distributed systems like Hadoop a big plus', '       5. Intermediate knowledge of Cloud Computing with certification from AWS /GCP/ Azure'], 'Formal Education:-->18': ['       â\\x96ª   Required: Bachelorâ\\x80\\x99s degree in Computer Science or related field', '       â\\x96ª   Required: Specialised certification in BI/Data Analytics/Big Data', '       â\\x96ª   Preferred:', '           -   Professional certification & knowledge in at Hadoop / RedShift/ Azure HDI/ Azure', '               Data Lake or any ELT / ETL Tool', '           -   Intermediate knowledge of Cloud Computing with certification from AWS /GCP/', '               Azure']}\n",
      "1\n",
      "{}\n",
      "2\n",
      "123\n",
      "AI\n",
      "Extracting project information...\n",
      "['Istanbul- Email me on Indeed : http : //www.indeed.com/r/Ipek-Kizil/afa469699fd3c63cA detail-oriented data scientist possess an extensive analytical skills , and a significant ability to workin team environments with three years of academic and two years of industry experience in machinelearning and data science.Work Experience']\n",
      "['etstur ( travel and tour company ) - Istanbul , TurkeyFebruary 2017 to October   Built a personalized recommendation engine ( based on hybrid filtering ) to recommend inspiring andrelevant hotels to the user by using deep neural networks which increased hotel bookings rates by27 % .', 'Developed a customer clustering module by using RFM Analysis .', 'The clusters are generated by usingk-means and rules are extracted with the decision tree .', 'The clusters are used for campaign and targetgeneration which increased targeted sales by 20 % .Education']\n",
      "['.Zirve University - TurkeyOctober 2010 to September 2015SkillsMachine Learning ( 5 years ) , Deep Learning ( 3 years ) , Artificial Intelligence ( 5 years ) , Python ( 5 years ) , R ( 3 years ) , Java ( 6 years ) , Spark ( 2 years ) , Scala ( 2 years ) , Sql ( mysql , pl-sql , hive-sql ) ( 3 years ) , Bash ( 5 years ) , Google Analytics ( 3 years ) , Google Cloud Services ( 2 years ) , Tensorflow ( 3 years ) , Spss ( 1year ) Linkshttps : //github.com/kizilipekhttps : //www.linkedin.com/in/ipekkizilAdditional InformationDependant Visa Holder .']\n",
      "Extracting total workex and relevant workex years...\n",
      "Forming workex sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iss-user/anaconda3/envs/iss-env-py3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting job information...\n",
      "{}\n",
      "1\n",
      "{}\n",
      "2\n",
      "123\n",
      "AI\n",
      "Extracting project information...\n",
      "['Istanbul- Email me on Indeed : http : //www.indeed.com/r/Ipek-Kizil/afa469699fd3c63cA detail-oriented data scientist possess an extensive analytical skills , and a significant ability to workin team environments with three years of academic and two years of industry experience in machinelearning and data science.Work Experience']\n",
      "['etstur ( travel and tour company ) - Istanbul , TurkeyFebruary 2017 to October   Built a personalized recommendation engine ( based on hybrid filtering ) to recommend inspiring andrelevant hotels to the user by using deep neural networks which increased hotel bookings rates by27 % .', 'Developed a customer clustering module by using RFM Analysis .', 'The clusters are generated by usingk-means and rules are extracted with the decision tree .', 'The clusters are used for campaign and targetgeneration which increased targeted sales by 20 % .Education']\n",
      "['.Zirve University - TurkeyOctober 2010 to September 2015SkillsMachine Learning ( 5 years ) , Deep Learning ( 3 years ) , Artificial Intelligence ( 5 years ) , Python ( 5 years ) , R ( 3 years ) , Java ( 6 years ) , Spark ( 2 years ) , Scala ( 2 years ) , Sql ( mysql , pl-sql , hive-sql ) ( 3 years ) , Bash ( 5 years ) , Google Analytics ( 3 years ) , Google Cloud Services ( 2 years ) , Tensorflow ( 3 years ) , Spss ( 1year ) Linkshttps : //github.com/kizilipekhttps : //www.linkedin.com/in/ipekkizilAdditional InformationDependant Visa Holder .']\n",
      "Extracting total workex and relevant workex years...\n",
      "Forming workex sentences...\n",
      "Extracting job information...\n",
      "{'About Health Sciences Authority (HSA)-->1': ['At the Health Sciences Authority (HSA), we recognise the enormous challenge posed today by the', 'biomedical sciences and the blurring of boundaries between healthcare products resulting from', 'increasing convergence in the application of medical technology. It is right here in HSA, where we are', 'uniquely equipped to meet this challenge. A statutory board formed on 1 April 2001, we play a vital', 'role in supporting healthcare services and regulation, serving the administration of justice and', 'enhancing safety in our community. We are responsible for the quality, safety and efficacy of', 'medicines, medical devices, blood and its products and all health-related products available in', 'Singapore. We provide a comprehensive regulatory service for the evaluation and marketing approval', 'of all therapeutic products. We also provide scientific, investigative and analytical support for vital', 'governmental functions such as forensic expertise for the courts, drug and criminal investigations and', 'the regulation of food safety and industrial and environmental health.'], 'Job Description-->2': ['â\\x80¢   Interact closely with research project team which includes healthcare professionals, academics', '    and IT system vendor.', 'â\\x80¢   Conceptualise, develop and integrate artificial intelligence algorithms from big healthcare data', '    sets that will be fed into various business programs.', 'â\\x80¢   Build intuitive dashboards that help visualize and answer complex business problems.'], 'Requirements-->3': ['â\\x80¢   Undergraduate or degree holder, preferably in computer science, machine learning, information', '    technology, business analytics or related disciplines.', 'â\\x80¢   At least 2 yearsâ\\x80\\x99 experience with programming in Python.', 'â\\x80¢   Good knowledge in R, Java, SQL, Stata, machine learning algorithms and/or natural language', '    processing will be an advantage.', 'â\\x80¢   Development and implementation of machine learning algorithms, extract information from', '    websites, meta data management, data transformation, and data integration.', '    For applicant who is interested, please submit the resume to the hiring manager and information', '    as follows:', '        ï\\x83\\x98 Name: Ms. Ang Pei San (Regulatory Consultant, Common Vigilance Branch)', '        ï\\x83\\x98 ANG_Pei_San@hsa.gov.sg', '\\x0c']}\n",
      "1\n",
      "{}\n",
      "2\n",
      "123\n",
      "AI\n",
      "Extracting project information...\n",
      "['Istanbul- Email me on Indeed : http : //www.indeed.com/r/Ipek-Kizil/afa469699fd3c63cA detail-oriented data scientist possess an extensive analytical skills , and a significant ability to workin team environments with three years of academic and two years of industry experience in machinelearning and data science.Work Experience']\n",
      "['etstur ( travel and tour company ) - Istanbul , TurkeyFebruary 2017 to October   Built a personalized recommendation engine ( based on hybrid filtering ) to recommend inspiring andrelevant hotels to the user by using deep neural networks which increased hotel bookings rates by27 % .', 'Developed a customer clustering module by using RFM Analysis .', 'The clusters are generated by usingk-means and rules are extracted with the decision tree .', 'The clusters are used for campaign and targetgeneration which increased targeted sales by 20 % .Education']\n",
      "['.Zirve University - TurkeyOctober 2010 to September 2015SkillsMachine Learning ( 5 years ) , Deep Learning ( 3 years ) , Artificial Intelligence ( 5 years ) , Python ( 5 years ) , R ( 3 years ) , Java ( 6 years ) , Spark ( 2 years ) , Scala ( 2 years ) , Sql ( mysql , pl-sql , hive-sql ) ( 3 years ) , Bash ( 5 years ) , Google Analytics ( 3 years ) , Google Cloud Services ( 2 years ) , Tensorflow ( 3 years ) , Spss ( 1year ) Linkshttps : //github.com/kizilipekhttps : //www.linkedin.com/in/ipekkizilAdditional InformationDependant Visa Holder .']\n",
      "Extracting total workex and relevant workex years...\n",
      "Forming workex sentences...\n",
      "0\n",
      "0\n",
      "0\n",
      "Running time: 0.32886385 Mins\n"
     ]
    }
   ],
   "source": [
    "from ipa import CoverLetterGenerator\n",
    "\n",
    "os.chdir(CURRENT_PATH)\n",
    "\n",
    "# jd_files = ['/home/iss-user/Desktop/S-IPA-WS-UAT/part2/JobApplicationAssistant/jd/0.pdf', '/home/iss-user/Desktop/S-IPA-WS-UAT/part2/JobApplicationAssistant/jd/1.pdf']\n",
    "\n",
    "gen = CoverLetterGenerator(resume_file_path,jd_files,name,phone,email_info['email'])\n",
    "\n",
    "import time\n",
    "starttime = time.clock()\n",
    "cover_letters = gen.generate()\n",
    "endtime = time.clock()\n",
    "print('Running time: %s Mins'%((endtime-starttime)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/media/sf_vm_shared_folder/S-IPA-WS-UAT/part2/JobApplicationAssistant/ipa/coverletter_20200306/templates_0.pdf', '/media/sf_vm_shared_folder/S-IPA-WS-UAT/part2/JobApplicationAssistant/ipa/coverletter_20200306/templates_1.pdf', '/media/sf_vm_shared_folder/S-IPA-WS-UAT/part2/JobApplicationAssistant/ipa/coverletter_20200306/templates_2.pdf']\n"
     ]
    }
   ],
   "source": [
    "# if the result is empty, that means your resume doesn't match those job postions, don't worry.\n",
    "# You can use your own resume\n",
    "print(cover_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "for index,cletter in enumerate(cover_letters):\n",
    "    shutil.copy(cletter,\n",
    "            './coverletter/coverleter_'+str(index)+\".pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success alertdanger\" style=\"margin-top: 20px\">\n",
    "    <h1>\n",
    "        Third: Send back application Email\n",
    "    </h1>\n",
    "    <p>\n",
    "        In this part, we use both pure python method and tagui to send the email to the hiring company\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Send email by Python:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib\n",
    "import imghdr\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.image import MIMEImage\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.application import MIMEApplication\n",
    "import random\n",
    "\n",
    "imgType_list = {'jpg','bmp','png','jpeg','rgb','tif'}\n",
    "\n",
    "# def send(sender_account,sender_password,toaddrs,email_text):\n",
    "#     try:\n",
    "#         server = smtplib.SMTP_SSL('smtp.gmail.com', 465)\n",
    "#         server.ehlo()\n",
    "#         server.login(sender_account, sender_password)\n",
    "#         server.sendmail(sender_account, toaddrs, email_text)\n",
    "#         server.close()\n",
    "#         print('Email sent!')\n",
    "#     except:\n",
    "#         print('Something went wrong...') \n",
    "\n",
    "def send(sender_account,sender_password,toaddrs,email_text):\n",
    "    try:\n",
    "        server = smtplib.SMTP('smtp.office365.com', 587)\n",
    "        server.starttls()\n",
    "        server.login(sender_account, sender_password)\n",
    "        print ('server working fine')\n",
    "        server.sendmail(sender_account, toaddrs, email_text)\n",
    "        server.close()\n",
    "        print('Email sent!')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('Something went wrong...') \n",
    "\n",
    "def sendmail(sender_account,sender_password,toaddrs,subject,content,attachments):\n",
    "\n",
    "    m = MIMEMultipart()\n",
    "    \n",
    "    textApart = MIMEText(content)\n",
    "    \n",
    "    m.attach(textApart)\n",
    "    \n",
    "    \n",
    "    for attach in attachments:\n",
    "        if imghdr.what(attach) in imgType_list:\n",
    "            imageApart = MIMEImage(open(attach, 'rb').read(), attach.split('.')[-1])\n",
    "            imageApart.add_header('Content-Disposition', 'attachment', filename=attach)\n",
    "            m.attach(imageApart)\n",
    "        else:\n",
    "            docApart = MIMEApplication(open(attach, 'rb').read())\n",
    "            docApart.add_header('Content-Disposition', 'attachment', filename=attach)\n",
    "            m.attach(docApart)\n",
    "            \n",
    "    m['Subject'] = subject\n",
    "    \n",
    "    send(sender_account,sender_password,toaddrs,m.as_string()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bwbw75@gmail.com']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "server working fine\n",
      "Email sent!\n",
      "server working fine\n",
      "Email sent!\n",
      "server working fine\n",
      "Email sent!\n"
     ]
    }
   ],
   "source": [
    "for index,_ in enumerate(cover_letters):\n",
    "    sent_from = email_info['email']\n",
    "    to = [random.choices(company_emails)]\n",
    "    subject = 'Job application - cover letter & resume (Python)'\n",
    "    body = \"Dear Sir/Madam, I write to you to apply for this position! \\n\\n- Regards,\\n\" + name\n",
    "    attachments = ['./coverletter/coverleter_'+str(index)+\".pdf\",'./resume/resume.pdf']\n",
    "    sendmail(email_info['email'],email_info['password'],to,subject,body,attachments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n",
    "    <h1>\n",
    "         Workshop Quiz:\n",
    "    </h1>\n",
    "    <p>\n",
    "         Send email by TagUI\n",
    "    </p>    \n",
    "    <p>\n",
    "         Recall \"CSS Selector Exericse in earlier workshop --- use the Bing Image Search to search the related image\" about How to use TagUI upload file\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or use below 'filling the blank' coding template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sendemail_tagui_outlook(email_account,email_pwd,to,subject,body,attachments):\n",
    "    try:\n",
    "        loginEmail_outlook(email_account,email_pwd)\n",
    "        t.click(\"//button[contains(@class,'ms-Button') and contains(string(), 'New message')]\")\n",
    "        t.wait(2)\n",
    "        t.type(\"//input[contains(@class, 'ms-BasePicker-input')]\",\" \".join(to))\n",
    "        t.wait(2)\n",
    "        t.click(\"//input[@id='subjectLine0']\")\n",
    "        t.type(\"//input[@id='subjectLine0']\",subject)\n",
    "        t.wait(2)\n",
    "        t.click(\"//div[@role='textbox']\")\n",
    "        t.type(\"//div[@role='textbox']\",body)\n",
    "        for file in attachments:\n",
    "            t.upload(\"div>input[type='file']+input\",file)\n",
    "\n",
    "        t.click(\"//button[contains(@class,'ms-Button') and contains(string(), 'Send')]\")\n",
    "        t.wait(10)\n",
    "    finally:\n",
    "        t.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,_ in enumerate(cover_letters):\n",
    "    sent_from = email_info['email']\n",
    "    to = random.choices(company_emails)\n",
    "    subject = 'Job application - cover letter & resume (TagUI)'\n",
    "    body = \"Dear Sir/Madam, I write to you to apply for this position! \\n\\n- Regards,\\n\" + name\n",
    "    attachments = ['./coverletter/coverleter_'+str(index)+\".pdf\",'./resume/resume.pdf']\n",
    "#    sendmail(email_info['email'],email_info['password'],to,subject,body,attachments)\n",
    "    sendemail_tagui_outlook(email_info['email'],email_info['password'],to,subject,body,attachments) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncommnet below, then press Shift+Enter for solution\n",
    "# codehelper.hint_for_ipa_exercise_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "    <a href=\"https://github.com/isa-ipa\">\n",
    "        <img src=\"\" width=\"60\" align=\"right\">\n",
    "     </a>\n",
    "     <h1>\n",
    "         End of Workshop\n",
    "     </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
