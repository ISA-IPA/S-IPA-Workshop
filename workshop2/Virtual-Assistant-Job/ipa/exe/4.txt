                                               Interested candidates please email resumes directly to gabrielle.loh@leap.asia




DELIVERY CONSULTANT – Primary focus – Data Analytics
JOB DESCRIPTION
Department:                     LEAP Delivery Team

                                Senior Specialist – Professional Services & Onboarding
Job Title:
                                (Delivery Consultant – Data Analytics)


The Ideal Candidate
You are a highly motivated, dynamic and adaptable team contributor who thrives in an innovative,
performance-oriented environment. Continual learning is everything and you want to be a key
contributor in a team full of diverse, experienced technology and business professionals. Deep down
you have a passion for life, embrace change and thrive in a creative environment. You understand
what motivates customers and team members alike and you find solutions to their problems that are
economic, strategic and elegant.

You enjoy and have experience in both “hands-on technical” and “business/data analysis” roles.
You are excited by working with data analytics with a focus on efficiency, simplicity and building high
impact customer features.

You may have been called a Power User, Solution Specialist, or Architect. You have also been a software
developer and have experience managing and serving customers. You understand that the work you do
will change how organizations and the industry can access, explore, and execute data. Towards this
end you will be responsible for engaging with our customers to “implement Datameer solutions”
among other analytics solutions and help users from various business roles leverage it effectively to
solve their technical and strategic needs. For e.g.,
     ▪ Help Data Engineers get ahead of all their data demands, quickly transforming raw data into
         analytics-ready datasets
     ▪ Understand needs of Business Analysts to access more data and get answers to their questions
         in hours, not weeks. Empower and help them shape data with point-and-click tools and start
         discovering business-changing insights.
     ▪ Work with Data Scientists to help them explore all the data for agile and more accurate ML and
         AI projects, performing point-and-click algorithmic and statistical analysis for faster, easier
         feature engineering.

You understand what motivates customers and team members alike and you find solutions to their
problems that are economic, strategic and elegant.

Joining the LEAP team gives you the opportunity to: work on disruptive products and technologies still
in its very early stages, solving challenging problems that will revolutionize enterprise computing in
the cloud.

As a key technologist and practitioner, in the Data Analytics space you will be sought after for your
knowledge by your colleagues, peers and by our customers for your expertise and insights.

Your Purpose:
In this role, you will be a key member of LEAP’s Professional Services Organization, and the point
person for Data Analytics.
As the Senior Data Analytics Specialist, you will own and manage the implementation of analytics
solutions for our customers. Leveraging your experience and insights into how organizations access,
explore, and execute data you will engage with our customers to “implement Datameer solutions”
among other analytics solutions and help users from various business roles leverage it effectively to
solve their technical and strategic needs. For example,
    ▪ Help Data Engineers get ahead of all their data demands, quickly transforming raw data into
         analytics-ready datasets
    ▪ Understand needs of Business Analysts to access more data and get answers to their questions
         in hours, not weeks. Empower and help them shape data with point-and-click tools and start
         discovering business-changing insights.
    ▪ Work with Data Scientists to help them explore all the data for agile and more accurate ML and
         AI projects, performing point-and-click algorithmic and statistical analysis for faster, easier
         feature engineering.

The Delivery Consultant (Analytics) will drive implementation, adoption, retention of Datameer and
associate solutions, in a customer centric manner to ensure overall success and satisfaction of your
customers.


You Responsibilities (approximately 6-10):

The areas of responsibility can be broadly divided into the following categories:

Consulting
   ▪ Lead customer teams and projects for our customers; be the face of Datameer to the project
        team during your scoped project.
   ▪ Interface with customers to gather requirements and articulate technical design of a solution
        to customer.
   ▪ Conceptualization, Design (both High Level & Low Level) of comprehensive Data Analytics –
        Big Data Solutions.
   ▪ Implementation of solutions and products of different types (with a focus on Datameer
        Solutions) during all stages of the project lifecycle including Technical Design specification,
        Integration of the solution, Operationalization (Training & process change), Customer
        Adoption and Business Value Realisation
   ▪ Create strong relationships, train others and evangelize your findings and implications.
   ▪ Scope project work, maintain project status, communicate status, issues, risks, and escalate as
        appropriate within Datameer and with Customer teams.
   ▪ Interface and collaborate with customer and Datameer team members both in project and
        outside, including other consultants and program management.
   ▪ Provide hands on implementation, troubleshooting, and instruction in a customer facing role.
   ▪ Estimate efforts required to deliver a fully tested solution to customers, this may include
        integrations leveraging SDK, REST API’s, or other programmatic approaches.

Technical
   ▪ “Full Datameer lifecycle ownership” including installation through to analytical business
       outcomes; this requires a broad range of skills in the areas of analytics, data management,
       programming, and infrastructure architecture.
   ▪ Integrate Datameer with tools and cloud-based platforms within the big data ecosystem (e.g.
       Hadoop, Spark, Tez, Azure HDI, Amazon EMR, RedShift, Google DataProc etc…).
   ▪ Design and develop plugins and extension services to aid customer users in data discovery,
       data preparation and analytics use cases.
   ▪ Interface with Datameer engineering groups to initiate product changes; be the customer
       advocate and represent the business to technology and technology to business.
    ▪   Design, build and maintain distributed data processing components driving the core of the
        Datameer application stack.
   ▪ Influence product strategy and help drive product roadmap while developing cloud native
        analytics features against multiple public cloud platforms.
   ▪ Provide architectural guidance for both on-premise and cloud rollouts.
   ▪ Assist with application migrations of Datameer and guide strategy for data migrations.
Analytics
   ▪ Lead business and data analytics teams to identify and define valuable outcomes.
   ▪ Design, build, and mentor customer use cases and analytics.
   ▪ Provide best practices and tools to assist with data preparation and ETL/ELT project work.
   ▪ Hands on experience of conducting due diligence, data analysis and dependency assessment
        required for successfully delivering the project.
   ▪ Participate in contract negotiation, proof of value execution and other late-stage presales
        activities
   ▪ Should work in agile manner using backlogs, sprints and Kanban
   ▪ Able to assist in proposal writing, including proactive input for proposals and RFI/RFP
        responses
   ▪ Accountable for implementation and customer success


Preferred Experiences

        ▪   5-6 years of relevant experience in consulting, technical support, professional services, or
            systems engineering in a customer facing role.
        ▪   At least 3-5 years software programming experience. Preferably with Java and related JVM
            technologies.
        ▪   Knowledge of professional software engineering best practices for the full software
            development life cycle.
        ▪   Applied experience with analytical programming such as Python or R to create data
            pipelines, machine learning models, or business intelligence discoveries. (Good to Have)
        ▪   Experience with cloud data technologies like EC2, EMR, RedShift, Azure HDI, Azure Data
            Lake.
        ▪   Proficiency in Linux operating systems including shell script authoring; experience with
            distributed systems like Hadoop a big plus
        ▪   Experience with Big Data related tools and technologies: MapReduce/Tez, HDFS,
            HBase, Hive, Hadoop, Spark and Cloud Infrastructure providers: AWS, Azure, Google Cloud
            will be considered an asset.
        ▪   Experience with distributed data processing, in memory technologies, data flow
            optimization, distributed search, cluster resource management, etc.
        ▪   Familiarity with SQL and NoSQL databases (i.e. MySQL, Spark, etc.), data streaming and
            integrating unstructured data will be plus.
        ▪   Analytical experience, understanding the value that data can offer to a business unit is
            preferred.
        ▪   Ability to work and thrive in a fast-paced environment, learn rapidly and master diverse
            technologies and techniques. Willingness to roll up the sleeves in a fast-paced, highly
            varied environment
        ▪   Demonstrated excellence in the following three categories:
             o Consulting: discovery, analysis, listening, communication, and project leadership
             o Analytics: given a dataset, you can extract insights and craft a compelling
                 presentation
             o Technical: proven comfort getting your hands dirty with SQL, relational databases,
                 APIs
        ▪   Strong interpersonal and collaboration skills; proven ability to build relationships
       ▪   Strong executive presentation and persuasion skills; excellent deliverable creation
           and editing skills. Be prepared to show samples or present
       ▪   Experience with Agile development teams and excellent interpersonal skills.
       ▪   Demonstrated experience with agile project management and comfort with project
           management concepts.
       ▪   Organized thinker, high level of communication to people of various technical skill set and
           acumen.
       ▪   Availability to travel to customer sites; up to 50%+ travel.
       ▪   Strong Communication Skills in English; addnl. ASEAN languages a plus


Must Have Requirements
       1. Conceptualization, Design (both High Level & Low Level) of comprehensive Data Analytics
          – Big Data Solutions.
       2. Lead business and data analytics teams to identify and define valuable outcomes.
       3. Design, build, and mentor customer use cases and analytics.
       4. Tool & Solution Implementation and Use.
       5. Provide best practices and tools to assist with data preparation and ETL/ELT project
          work.
       6. Hands on experience of conducting due diligence, data analysis and dependency
          assessment required for successfully delivering the project.
       7. Professional certification & knowledge in at Hadoop / RedShift/ Azure HDI/ Azure Data
          Lake or any ELT / ETL Tool



Good to Have Requirements
       1. Applied experience with analytical programming such as Python or R to create data
          pipelines, machine learning models, or business intelligence discoveries.
       2. Experience with cloud data technologies like EC2, EMR, RedShift, Azure HDI, Azure Data
          Lake.
       3. Experience with Big Data related tools and technologies: MapReduce/Tez, HDFS,
          HBase, Hive, Hadoop, Spark and Cloud Infrastructure providers: AWS, Azure, Google Cloud
          will be considered an asset.
       4. Proficiency in Linux operating systems including shell script authoring; experience with
          distributed systems like Hadoop a big plus
       5. Intermediate knowledge of Cloud Computing with certification from AWS /GCP/ Azure


Formal Education:

       ▪   Required: Bachelor’s degree in Computer Science or related field
       ▪   Required: Specialised certification in BI/Data Analytics/Big Data
       ▪   Preferred:
           -   Professional certification & knowledge in at Hadoop / RedShift/ Azure HDI/ Azure
               Data Lake or any ELT / ETL Tool
           -   Intermediate knowledge of Cloud Computing with certification from AWS /GCP/
               Azure
